/*
 * Copyright 2016 The BigDL Authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package com.intel.analytics.bigdl.nn

import com.intel.analytics.bigdl.nn.ops.Gather
import com.intel.analytics.bigdl.tensor.Tensor
import com.intel.analytics.bigdl.utils.T
import org.scalatest.{FlatSpec, Matchers}

class EmbeddingSharedWeightsSpec extends FlatSpec with Matchers {
  val outputExpected = Tensor[Float](
    T(T(T(-1.1599494, 0.760163, -0.40056285, -1.1687254,  -0.9138438,
      -0.36700436, 1.823892, -1.1820021,   0.5161278,  -0.9247919),
      T(-1.3161435, 0.3335442, -1.717504,    0.1719768,  -1.0396556,
        1.1057091, -1.1911561, 1.0511508,   0.182776,    1.0882055),
      T( 0.4910144, -0.15613313, 1.4748657,   0.43576995,  2.1953826,
        -0.835677, -1.2184695, 0.80400825,  1.1463742,  -1.0150346),
      T( 0.3996748, 0.9506703, 1.1250867,  -0.8667602,  -1.1034116,
        2.3314137, 1.1097203, 0.71407086,  1.7064031,   1.8066634),
      T(-0.85047543, -2.599748, 1.2207254,  -2.0881205,  -0.19363593,
        -1.276643, -0.02703438, 1.0847754,  -0.65506506,  0.4604092),
      T(-0.05895612, 0.26545224, 0.2933284,   0.42852548,  0.7240954,
        0.1287913, 1.4303886, 0.6864762,   2.1965477,   0.51878077),
      T( 0.71048903, -1.5525047, -1.3863628,   0.3238582,   0.81226677,
        0.19209047, -0.23002781, -0.6363123,   1.0210168,   0.65428704),
      T(-0.28552356, 0.5651177, -0.79568213,  0.07561763, -1.0208569,
        1.0577098, -1.2571571, 0.42046708, -2.5739086,   0.9694715),
      T( 0.9546018, 1.5931981, -0.44433123, -0.33717924,  0.7956628,
        0.50112695, -0.22244534, 1.7690458,  -0.898172,    1.8298535),
      T( 0.0090594, 0.01880967, 1.7577182,  -0.6437277,   0.3668765,
        0.15854552, -0.6759979, 0.53726906, -1.2015843,  -1.7854905),
      T(-0.7219142, -0.10999311, 1.5652132,  -0.3543373,  -1.1179914,
        0.34499285, 0.6499864, -1.6437156,   0.9259236,  -0.476595),
      T(-0.03769343, 0.52877223, -0.2173391,   1.1371078,  -0.59003806,
        1.5462487, -0.6499737, -1.0323933,   0.197083,    0.68658423)),
      T(T(-0.09307563, -0.55122334,  1.2353249,  -1.1112415,  -0.05812125,
        0.6815989, 0.691256, -0.77127314, -0.10874277,  0.86469096),
        T(-0.7219142, -0.10999311, 1.5652132,  -0.3543373,  -1.1179914,
          0.34499285, 0.6499864, -1.6437156,   0.9259236,  -0.476595),
        T(-0.6199275, -0.47378838, 0.8650373,   0.27147385,  0.3707318,
          -0.19951358, 0.7916733, -0.33982825,  0.18631981, -1.5471507),
        T( 0.59465605, -0.39653215, -2.6116316,  -1.1501349,  -1.1990832,
          0.41783467, -0.22730026, 0.3142501,  -0.5856289,  -0.10131569),
        T(-0.13715318, -0.7494559, -0.6900695,  -1.2961766,  -0.15865716,
          1.3895628, 0.90216327, -1.311854,   -0.15067385, -0.6309336),
        T(-0.03769343, 0.52877223, -0.2173391,   1.1371078,  -0.59003806,
          1.5462487, -0.6499737, -1.0323933,   0.197083,    0.68658423),
        T(-0.17206922, 1.0948895, 1.0302242,  -0.9556774,  -0.07595373,
          -1.4860637, 2.5717487, -1.7536626,   1.1291388,   0.97053045),
        T( 1.0521581, 0.65624017, -1.290194,    0.64157075, -0.40509227,
          -0.65354455, 0.4234868, -1.3410776,   0.05931387, -0.5433723),
        T( 0.17671813, 0.8072072, 1.3246931,   0.39417782, -0.23720965,
          0.9679637, -1.0234876, -0.8661555,  -1.5812052,  -0.37635),
        T(-1.1599494, 0.760163, -0.40056285, -1.1687254,  -0.9138438,
          -0.36700436, 1.823892, -1.1820021,   0.5161278,  -0.9247919),
        T( 0.3996748, 0.9506703, 1.1250867,  -0.8667602,  -1.1034116,
          2.3314137, 1.1097203,   0.71407086,  1.7064031,   1.8066634),
        T(-0.03769343, 0.52877223, -0.2173391,   1.1371078,  -0.59003806,
          1.5462487, -0.6499737,  -1.0323933,   0.197083,    0.68658423))))


  private val weights = Tensor[Float](
    T(T( 0.33296704, -0.2825494,   0.09811679,  0.3889332,  -0.19899155,  0.1799927,
      -0.5091036,   0.34838164, -0.25564954,  0.02378663),
      T(-0.3668082,   0.24038465, -0.1266691,  -0.3695834,  -0.28898278, -0.11605697,
        0.5767653,  -0.37378186,  0.16321395, -0.29244485),
      T(-0.0294331,  -0.17431213,  0.390644,   -0.3514054,  -0.01837955,  0.2155405,
        0.21859433, -0.24389797, -0.03438748,  0.2734393),
      T(-0.4162011,   0.10547593, -0.5431225,   0.05438384, -0.32876796,  0.3496559,
        -0.37667665,  0.33240306,  0.05779885,  0.34412077),
      T(-0.2282893,  -0.03478288,  0.49496388, -0.11205129, -0.35353994,  0.10909632,
        0.20554374, -0.5197885,   0.29280275, -0.15071258),
      T( 0.15527238, -0.04937363,  0.46639347,  0.13780256,  0.6942409,  -0.2642643,
        -0.3853139,   0.25424972,  0.36251536, -0.3209821),
      T(-0.19603829, -0.14982504,  0.2735488,   0.08584757,  0.11723569, -0.06309173,
        0.25034907, -0.10746313,  0.0589195,  -0.48925203),
      T( 0.12638827,  0.30062833,  0.35578364, -0.27409363, -0.34892938,  0.7372578,
        0.35092437,  0.22580902,  0.53961205,  0.57131714),
      T( 0.18804675, -0.12539448, -0.82587045, -0.3637046,  -0.3791834,   0.13213092,
        -0.07187865,  0.09937461, -0.18519212, -0.03203883),
      T(-0.26894394, -0.82211244,  0.38602728, -0.66032165, -0.06123305, -0.40370998,
        -0.00854902,  0.34303612, -0.20714976,  0.14559416),
      T(-0.04337164, -0.23699877, -0.21821913, -0.40988702, -0.0501718,   0.43941835,
        0.28528908, -0.41484466, -0.04764726, -0.19951871),
      T(-0.01864356,  0.08394337,  0.09275859,  0.13551165,  0.22897907,  0.04072738,
        0.4523286,   0.21708283,  0.6946094,   0.16405289),
      T(-0.01191971,  0.16721246, -0.06872866,  0.35958508, -0.18658641,  0.48896676,
        -0.20553973, -0.32647145,  0.06232312,  0.217117),
      T( 0.22467636, -0.49094507, -0.4384064,   0.10241295,  0.2568613,   0.06074434,
        -0.07274118, -0.20121962,  0.32287386,  0.20690373),
      T(-0.05441307,  0.34623447,  0.3257855,  -0.30221173, -0.02401868, -0.4699346,
        0.81325835, -0.5545568,   0.35706505,  0.30690867),
      T(-0.09029048,  0.17870592, -0.25161678,  0.02391239, -0.3228233,   0.33447722,
        -0.39754796,  0.13296336, -0.81394136,  0.3065738),
      T( 0.33272162,  0.20752136, -0.40799516,  0.20288248, -0.12810142, -0.20666893,
        0.13391829, -0.42408597,  0.01875669, -0.1718294),
      T( 0.3018716,   0.50381345, -0.14050987, -0.10662544,  0.25161067,  0.15847026,
        -0.07034339,  0.5594214,  -0.28402692,  0.5786505),
      T( 0.05588318,  0.25526133,  0.41890472,  0.12464997, -0.07501227,  0.306097,
        -0.3236552,  -0.27390242, -0.500021,   -0.11901231),
      T( 0.00286483,  0.00594814,  0.5558393,  -0.20356458,  0.11601654,  0.0501365,
        -0.2137693,   0.16989939, -0.37997434, -0.5646217)))

  "gather" should "correct" in {
    val vocab_size = 20
    val hidden = 10
    val batch = 2
    val length = 12
    val weight = Tensor[Float](vocab_size, hidden).fill(0.01f)
    val input = Tensor[Float](batch, length).fill(0.1f)

    val gather = new Gather[Float, Float]()

    val out = gather.forward(T(input, weight))

    println("done")
  }

  "look up table" should "correct" in {
    val arr = T(1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 4, 12, 2, 4, 6, 8, 10, 12, 14, 16, 18, 1, 7, 12)
    val input = Tensor[Float](arr).resize(Array(2, 12)).add(1.0f)

    val m = math.sqrt(10)
    val look = LookupTable[Float](20, 10)

    val out = look.forward(input)
    val gradInput = look.backward(input, out.contiguous())

    val tmp = 0
  }

  "EmbeddingSharedWeights" should "correct" in {
    val arr = T(1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 4, 12, 2, 4, 6, 8, 10, 12, 14, 16, 18, 1, 7, 12)
    val input = Tensor[Float](arr).resize(Array(2, 12)).add(1.0f)

    val look = new EmbeddingSharedWeights[Float](20, 10)

    look.weight.copy(weights)

    val out = look.forward(input)
    out should be(outputExpected)
    val gradInput = look.backward(input, out.contiguous())

    println("done")

  }
}
